# -*- coding: utf-8 -*-
"""Copy of Untitled24.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Fa4-Jfa4YCoF1VpNFvJpkjycAs79Uae3
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
!pip install ydata-profiling
from ydata_profiling import ProfileReport
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder,OneHotEncoder
from sklearn.metrics import classification_report,confusion_matrix,accuracy_score
from sklearn.ensemble import RandomForestClassifier

df=pd.read_csv('/content/Financial_inclusion_dataset.csv')
df.head(50)

print(df.shape)

print(df.info())

print(df.describe())

df.isna().sum()

df.duplicated().sum()

profile =ProfileReport(df, title='Financial Inclusion Dataset')
profile.to_notebook_iframe()

# Plot boxplots for numeric columns
fig, axes = plt.subplots(1, 2, figsize=(12, 5))
sns.boxplot(data=df, y="age_of_respondent", ax=axes[0]).set_title("Age of Respondent")
sns.boxplot(data=df, y="household_size", ax=axes[1]).set_title("Household Size")
plt.tight_layout()
plt.show()

df_encoded = pd.get_dummies(df, drop_first=True)

# Drop identifier columns
df_encoded = df.drop(columns=["uniqueid"])

df_encoded["bank_account"] = df_encoded["bank_account"].map({"Yes": 1, "No": 0})

# One-hot encode categorical features
df_encoded = pd.get_dummies(df_encoded, drop_first=True)

df_encoded.head()

# Define features and target
X = df_encoded.drop("bank_account", axis=1)
y = df_encoded["bank_account"]

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train Random Forest Classifier
clf = RandomForestClassifier(random_state=42)
clf.fit(X_train, y_train)

# Evaluate model
y_pred = clf.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
report = classification_report(y_test, y_pred, output_dict=True)
pd.DataFrame(report).transpose()

from sklearn.model_selection import RandomizedSearchCV

# Parameter distributions for random sampling
param_dist = {
    'n_estimators': np.arange(100, 500, 50),
    'max_depth': [None] + list(np.arange(5, 20, 5)),
    'min_samples_split': [2, 4, 6, 8],
    'max_features': ['auto', 'sqrt', 'log2']
}

# RandomizedSearch setup
random_search = RandomizedSearchCV(
    estimator=clf,
    param_distributions=param_dist,
    n_iter=25,  # Total random combinations to try
    scoring='accuracy',
    cv=5,
    verbose=1,
    random_state=42,
    n_jobs=-1
)

# Fit search to training data
random_search.fit(X_train, y_train)

# Best parameters & model
print("Best Parameters (Random):", random_search.best_params_)
best_random_model = random_search.best_estimator_

random_acc = accuracy_score(y_test, best_random_model.predict(X_test))

print("RandomizedSearchCV Accuracy:", random_acc)

feature_order = X_train.columns.tolist()

import pickle

with open ('random_search.pkl','wb') as file:
  pickle.dump(random_search,file)

#model='best_random_model'
#pickle.dump(random_search,open(model,'wb'))

#loaded_model=pickle.load(open('best_random_model','rb'))

